The goal of this section is to describe how we adapt it to be a malleable TOHTN planner by integrating it with Mallob, preserving both the completeness and scalability of CrowdHTN in the process. Before we get into the details, let's recall that CrowdHTN is already a moldable program according to the definition introduced in section \ref{prelim: malleability}, i.e., it may utilize any number of PEs as long as that number stays fixed during the run. We will now introduce a design that extends the parallel capabilities to achieve malleability. For this we need to address three main concerns.
\begin{itemize}
	\item Distributing the job information
	\item Integrating new PEs into a running job
	\item Dealing with PEs leaving the job while it runs
\end{itemize}
Due to the fact that we specifically integrate CrowdHTN with Mallob, in some parts we will have to refer to implementation details regarding how Mallob organizes the PEs assigned to a job as well as general message delivery.

\subsection{Distributing Jobs}
- grounded instance may be exponential in size
- exceedingly high communication cost
- lifted instance it is
	- sending a parsed instance - we still need to encode and decode it for sending
	- we would effectively have to build a parser for this
	- we already do have a parser
	- we simply encode the string and parse locally
	- not a core issue to us, so we go for ease of implementation

\subsection{Integrating New PEs Into Malleable CrowdHTN}
- work stealing makes this easy
- there is functionally no difference between a new PE and a PE which has locally run out of work
- no special handling required at all

\subsection{Handling PEs Leaving at Run Time}
- goal: complete and correct planner
- scalable
- work according to the 

- we need to distribute the problem description efficiently (as we need to do it time and time again)
	- efficiently here means little communication overhead
	- choose to do the lifted instance
	- ease of implementation, we do not see it as a core issue

- integrate new workers efficiently
	- work stealing is nice here

- deal with disappearing workers
	- either design a scheme to preserve global knowledge or be able to deal with loss of information
	- in our case we deal with loss of information
	- two parts: loosing information stored in the fringe of a terminated node and loosing messages of dying workers
	- loosing information stored in the fringes:
		- multiple options:
			- send back nothing, loose parts of the search space
			- send back the root, redo parts of the search (also, loop detection!)
			- send back everything, takes much communication
			
			- our loop detection scheme already implies that we loose parts of the search space and we have measures in place to deal with this fact (restarts)
			- for this reason we go with this approach
			
	- loosing information due to lost messages:
		- Mallob has a mechanism to return messages
		- however, messages can still be lost (return message and original sender dies in the meantime)
		- we could change Mallob to send such messages to the root worker
		- however, this would turn the root into a bottleneck
		- again, we have mechanisms in place to deal with overall loss of information without loosing completeness
		- at the same time, we need to adapt our handling of return messages to ensure all workers stay in a valid state and do not get stuck
		- the worker may be replaced
		
	- getting wrong information (worker dies, is replaced, gets message meant for old worker)
	
	- we loose the ability to detect UNPLAN