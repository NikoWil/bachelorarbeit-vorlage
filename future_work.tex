\subsection{A Common (TO)HTN Interface}
- be able to mix grounders, pruners, planners - maybe even loop detection!
- be able to combine different pruners - use a lifted pruner early and then plug in a grounder and grounded pruner afterwards
- PANDA seems to try to provide this
	- quite successful regarding the input format for HTN planning which finally makes planners easily comparable, advancing the state of the art
	- sadly not as successful for the rest of planning
- we believe their to be great potential in 

\subsection{Combine Pruning Approaches}
- HyperTensioN and Panda base their pruning on different paradigms
- HyperTensioN's pruning could be extended to work on grounded instances where it would have even more information available
- both these approaches are structurally different and could thus be used to compliment each other
- whether the better pruning would offset the increased runtime cost remains to be seen

\subsection{Advances runtime pruning techniques}
In section \ref{improv: loops and completeness} we saw the problems with current loop detection techniques regarding (TO)HTN planner completeness. Specifically, loop detection in heuristic progression search suffers from recursive tasks which introduce additional new tasks which have to be resolved after the recursive task itself. At the same time, the PANDA planner has shown that heuristic progression search with loop detection is a promising approach with state of the art performance \cite{holler2020htn}, \cite{holler2021loop}. As a result, we propose that we take the notion of loop detection and expand it to a more generalized definition of dynamic pruning. In the past we were restricted to filtering out search nodes that are duplicates and as such already known. For future research, we could instead look at tasks sets and see whether they are still feasibly performing productive work. As an example take a task $t$ which recursively resolves into two new instances of $t$. Additionally, let $\mathcal{Q}_t$ be the set of predicates which may be changed as a result of resolving $t$. Then any sequence of $t$ which has length at least $2^{\mathcal{Q}_t}$ will necessarily perform duplicate work and any resolution which leads to an even longer sequence of $t$ needs not be explored. \\
In this way, using improved dynamic pruning of unproductive task sequences may allow us to build planners which are both complete while at the same time realizing the performance gains seen in heuristic progression search.
\begin{comment}
- some planners are known to not be complete
- some planners can easily be shown to be complete
- we make a case in section \todo{Ref where we destroy our own heuristic and PANDA} that heuristic planners may not be complete
- to catch these cases planners may have to get more intelligent about which parts of the search space to cut off
- else we may have to adapt our search algorithms to enforce completeness at another level
- similarly we may achieve completeness by simply cutting off the search once we get too deep \todo{cite exponential max depth}
- however, this may be theoretically complete but also hits us with the full expense of an EXPSPACE-hard problem, i.e. we may never realistically reach this condition (except on very small problems)
- similarly it is not clear whether an algorithm like heuristic + plan length search gives us completeness in feasible time or more theoretically \todo{Compare with results once they arrive}
- HyperTensioN, a decidedly non-complete planner is also the best-rated planner in the IPC 2020
- maybe we need to have a full conversation on how much completeness we actually want/ need (or two separate categories of planners between 'HTN as a way to provide advice into planning domains \todo{quote Erol, I think?}' and 'HTN for the full power it provides')

- new loop detection techniques leading to planner completeness
\end{comment}

\subsection{Lifted Parallel Search}
- the Crowd way of performing relatively simple search does not work out in the end
- we can still see some scaling for the parallel case
- lifted planning could massively shrink our search space (by an exponential factor in the number of nodes!)
- lilotane provides much intelligence on how to perform lifted search
- same as HyperTensioN
- a lilotane-like behavior may be the best from a practical perspective, as it is more consistent
- a search-based formulation may be easier to both parallelize and adapt to a malleable context - any search may be plugged in where CrowdHTN currently resides

\subsection{Improvements Unlocked by a Shared Memory Implementation}
- we have decided to stay with CrowdHTN's way of performing grounding on-demand and just in time, as it lends itself particularly well to a malleable environment
- specifically, having to perform a big chunk of work that is not yet possible to lead to a plan would impose a problem on the efficiency of new and short-lived workers
- in a shared-memory environment, this could be done once by the root and then re-used by other workers, making better pruning and heuristics such as in PANDA available

\subsection{Global Loop Detection}
- we show how a global loop detection mechanism in (TO)HTN planning could work
- so far, we use a very simple heuristic (encounter a node twice) for which nodes to share
- more intelligent heuristics are probably helpful
- we are interested in search nodes often reached, less in recursive tasks (can be resolved locally)

\subsection{Intelligent Restarts}
- we perform restarts according to the harmonic series
- SAT solving already knows restarts, explore inner-outer and luby sequence for potentially better performance
