\subsection{Future Work}
\label{future work}
In this work we have shown how current loop detection mechanisms are insufficient to ensure planner completeness and how our own global loop detection scheme with restarts can improve overall performance. We will now give a short overview of ideas we encountered that may improve the capabilities of loop detection and further increase the performance of our distributed loop detection and restarting scheme. This is followed by ideas as to how information loss in a malleable environment may be better addressed.

\paragraph{Advanced dynamic pruning}
In section \ref{improv: completeness} we show that the current state of the art in loop detection can detect some but not all cases of recursion as it is present in hierarchical planning problems. We further show that this not only negatively affects the performance of our planners but may make planners based on heuristic DFS incomplete. \\
To deal with such cases, we could take the idea of detecting duplicate search nodes and generalize it into a notion of dynamic pruning of uninteresting nodes. Uninteresting here means that exploring this node will give us no new information about our planning problem. A duplicate search node is uninteresting as we have explored it before, obtaining all information that is available. However, a search node may also be uninteresting if it's open tasks is built such that we are guaranteed to perform unnecessary work when exploring it. Such a set of open tasks may contain a sequence of $k$ times task $t$, where the resolution of $t$ may only create actions and more instances of $t$ and affect at most $l$ predicates. If $k > 2^l$, then extending this sequence by more instances of $t$ is of no benefit. We could only create more instances of $t$ and resolving all open $t$ via actions would lead us through duplicate world states, performing unnecessary work. \\
More research would need to be put into detecting such cases to perform more intelligent pruning of search nodes. If done successfully, heuristic DFS may regain completeness if combined with this new scheme.
\begin{comment}
- some planners are known to not be complete
- some planners can easily be shown to be complete
- we make a case in section \todo{Ref where we destroy our own heuristic and PANDA} that heuristic planners may not be complete
- to catch these cases planners may have to get more intelligent about which parts of the search space to cut off
- else we may have to adapt our search algorithms to enforce completeness at another level
- similarly we may achieve completeness by simply cutting off the search once we get too deep \todo{cite exponential max depth}
- however, this may be theoretically complete but also hits us with the full expense of an EXPSPACE-hard problem, i.e. we may never realistically reach this condition (except on very small problems)
- similarly it is not clear whether an algorithm like heuristic + plan length search gives us completeness in feasible time or more theoretically \todo{Compare with results once they arrive}
- HyperTensioN, a decidedly non-complete planner is also the best-rated planner in the IPC 2020
- maybe we need to have a full conversation on how much completeness we actually want/ need (or two separate categories of planners between 'HTN as a way to provide advice into planning domains \todo{quote Erol, I think?}' and 'HTN for the full power it provides')

- new loop detection techniques leading to planner completeness
\end{comment}

\begin{comment}
\subsection{Lifted Parallel Search}
- the Crowd way of performing relatively simple search does not work out in the end
- we can still see some scaling for the parallel case
- lifted planning could massively shrink our search space (by an exponential factor in the number of nodes!)
- lilotane provides much intelligence on how to perform lifted search
- same as HyperTensioN
- a lilotane-like behavior may be the best from a practical perspective, as it is more consistent
- a search-based formulation may be easier to both parallelize and adapt to a malleable context - any search may be plugged in where CrowdHTN currently resides
\end{comment}

\paragraph{Global loop detection}
We show that a global loop detection scheme positively impacts the performance of our parallel TOHTN planner. So far we have only used a simple heuristic to determine when a search node is entered into the global filter, namely if it was twice encountered locally.
Better informed heuristics to determine when a node is likely interesting for other PEs could further improve the performance of our distributed loop detection scheme. Additionally, we could track search nodes whose subgraph has been fully explored and keep them in an additional global filter. This would increase the memory footprint as nodes would have to be kept around until we backtrack past them but such information could even be kept across restarts to further improve performance over time.

\paragraph{Intelligent restarts}
In both \ref{ld - completeness} and \ref{improv: completeness} we argue for the use of probabilistic restarts to guarantee the completeness of CrowdHTN. We perform restarts with probability $\frac{1}{t}$ at second $t$. This is only one of the possible ways to use restarts. \\
Restarts and restarting strategies to increase solver performance have played a role in SAT solving since the 1990s.
\cite{langley1992systematic} suggested the use of iterative sampling in AI planning systems, repeatedly exploring random paths up to a depth limit and restarting if no solution was found. 
Their work was adapted by \cite{crawford1994experimental} who employed the iterative sampling strategy for SAT solving. As a general restart strategy for increased performance, the Luby sequence was developed \cite{luby1993optimal} and has by now been adapted by SAT solvers \cite{huang2007effect}. By now a wide array of different restart strategies have been tried in SAT solvers. There are both static restart strategies, such as uniform intervals and based Luby schemes and dynamic strategies which incorporate run time information into their decision \cite{biere2015evaluating}. \\
We are eager to see how incorporating such restart schemes may affect the performance of hierarchical planners.

\begin{comment}
In SAT solving, restarts have long been an important part of solvers to increase their performance.

- we perform restarts according to the harmonic series
- SAT solving already knows restarts, explore inner-outer and luby sequence for potentially better performance

- \cite{langley1992systematic} suggests iterative sampling as an extreme form of restarts
- \cite{crawford1994experimental} uses restarts via iterative sampling for SAT solving
- \cite{gomes1998boosting} use restarts in planning, argue their use in combinatorial search
- \cite{biere2015evaluating}
- optimal restart points may be unknown
- frequent restarts may help in learning
- long times may be needed to find solutions
- show that luby is quite good
- different restart policies:
- static: uniform, geometric, luby
- dynamic: agility - prohibit restart depending on status, 
- \cite{luby1993optimal} propose the luby sequence as a strategy
- \cite{huang2007effect} use luby sequence in SAT
\end{comment}

\paragraph{Malleable communication schemes}
As we have seen in our evaluation, our malleable TOHTN planner struggles with the frequent reshuffling of PEs. This could be addressed either by changing Mallob s.t. message loss can be avoided completely or by designing new communication schemes that ensure no information is lost. This may be done by limiting communication to use the edges of the binary tree in which Mallob organizes the worker of a job and having parents guarantee that no information of their children is lost. Additional work would be needed to ensure that the guarantees of randomized work stealing still hold up in such an environment.
