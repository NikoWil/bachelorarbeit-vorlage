\subsection{Parallel and Distributed Computing Techniques}
- parallel and distributed computing has been investigated for many years
- also in fields related to hierarchical planning
- 
- we will revisit our overview on parallel graph search and parallel planning as introduced in \cite{bretl2021parallel}
- we expand by giving a short overview over parallel hierarchical planning from \cite{bretl2021parallel}

\subsubsection{Parallel Graph Search}
- many hierarchical planners such as HyperTensioN \cite{magnaguagno2020hypertension}, PANDA \cite{holler2020htn} and our own planner CrowdHTN \cite{bretl2021parallel} are based on some form of DFS
- parallel DFS has been investigated for over 30 years \cite{rao1987parallel, kumar1987parallel}
- in hierarchical planning our graph is often so large as to be only implicitly defined
- load balancing under these conditions was investigated by \cite{sanders1997lastverteilungsalgorithmen}

- load balancing is important, parallelism can lead to overhead \cite{fukunaga2018parallel}
	- search overhead: parallel implementation expands more nodes than a sequential one
	- synchronization overhead: processors are waiting for synchronization points
	- communication overhead: time spent on communication
- work sharing:
	- processors with work actively distribute it to processors without work
- work stealing:
	- processors without work "steal" work from processors with work
- important: where do you get work from/ give it to? Randomization!
- work stealing has less communication overhead than work sharing \cite{blumofe1999scheduling}

- work package: a node in our graph and all it's children
- TOHTN planning this is large, as the task network may get very big
- our own planner CrowdHTN uses work randomized stealing
- work stealing performance may degrade where duplicate states play a role \cite{fukunaga2018parallel}
- \cite{holler2021loop} shows duplicates are important in TOHTN planning

\subsubsection{Parallel Hierarchical Planning}
We already investigated parallel, moldable hierarchical planning before \cite{bretl2021parallel}. In our previous work, we investigated three different planners:
\begin{itemize}
	\item SHiP, a portfolio planner
	\item Mallotane, an integration of Lilotane and Mallob
	\item CrowdHTN, a search-based planner
\end{itemize}
Out of these three, SHiP performed overall best. As a portfolio planner, it is however limited by the number sequential planners with sufficiently different planning characteristics. It's performance only scales meaningfully for up to four cores. Second, we have Mallotane. Here we took the sequential SAT-based planner Lilotane and integrated it with Mallob as a SAT backend. This allowed us to parallelize the SAT solving part of Lilotane's planning. Mallotane, too, has limited scalability as instantiating the task network and pruning unreachable tasks are still sequential. Third, we created the new progression search planner CrowdHTN. It uses randomized work stealing for load balancing and performs random DFS to find a plan. While it performed overall worse than SHiP and Mallotane it has the highest theoretical potential for scalability, as it is fully parallel. A more detailed overview of CrowdHTN will be given later in \ref{prelim: crowdhtn}.\\
We are not aware of any work on malleable TOHTN planning. However, with the presence of malleable SAT solvers such as Mallob \cite{sanders2022decentralized} and Paracooba \cite{heisinger2020distributed} one could argue that Mallotane and any other SAT-based hierarchical planner can be made malleable. This is however limited by the fact that SAT-solving is only part of the work those planners perform which would limit scalability.